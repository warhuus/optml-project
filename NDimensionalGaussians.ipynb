{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import sklearn\n",
    "from sklearn.model_selection import RandomizedSearchCV, ShuffleSplit\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import torch\n",
    "\n",
    "import warnings\n",
    "#warnings.filterwarnings('ignore')\n",
    "#warnings.simplefilter('ignore')\n",
    "\n",
    "mpl.style.use('seaborn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ZORO import benchmarkfunctions\n",
    "from ZORO import optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensionality of data -- we tweak this to run our experiments\n",
    "dim = 1000             #10, 100, 1000, 10000\n",
    "informative = 1000     # 1,  10,  100,  1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification, make_blobs\n",
    "# Cluster of points normally distributed (std=1) about vertices\n",
    "# of an n_informative-dim hypercube with sides of length 2*class_sep\n",
    "\n",
    "# Features are ordered: n_informative, n_redundant, n_repeated, \n",
    "# then random noise\n",
    "def generate_samples(n_features, n_informative, n_samples=100):\n",
    "    return make_blobs(\n",
    "        n_samples=n_samples,\n",
    "        n_features=n_features,\n",
    "        centers=2,\n",
    "        \n",
    "    )\n",
    "    \"\"\"\n",
    "    return make_classification(\n",
    "        n_samples=n_samples, \n",
    "        n_features=n_features, \n",
    "        n_informative=n_informative,\n",
    "        n_redundant=0, \n",
    "        n_repeated=0, \n",
    "        n_classes=2, \n",
    "        n_clusters_per_class=1, \n",
    "        flip_y=0.01, \n",
    "        class_sep=2, \n",
    "        random_state=42,\n",
    "        shuffle=False\n",
    "    )\n",
    "    \"\"\"\n",
    "\n",
    "X, y = generate_samples(dim, informative)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot of Projection onto 2 Dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "X_reduced = pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=X_reduced[:,0], y=X_reduced[:,1], hue=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Separator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "clf = LinearSVC(random_state=42, max_iter=1000)\n",
    "clf.fit(X, y)\n",
    "print(\"Number of iterations\", clf.n_iter_)\n",
    "print(\"Accuracy:\", clf.score(X, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ZORO Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adversarial Attack Loss\n",
    "class AttackLoss(object):\n",
    "    '''An implementation of the sparse quadric function.'''\n",
    "    def __init__(self, predictor, lamb, norm, x_original, y_true, y_attack):\n",
    "        self.predictor = predictor\n",
    "        self.lamb = lamb\n",
    "        self.norm = norm\n",
    "        \n",
    "        self.x_original = x_original\n",
    "        self.y_true = y_true\n",
    "        self.y_attack = y_attack\n",
    "        \n",
    "    def __call__(self, x_attack):\n",
    "        ## (f(x + delta) - y_attack + y_true)^2 + lambda ||delta||_0\n",
    "        prediction = self.predictor.decision_function(x_attack)\n",
    "                \n",
    "        return (prediction - self.y_attack + self.y_true)**2 \\\n",
    "              + self.lamb * np.linalg.norm((x_attack - self.x_original), self.norm, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class AdaZOROExperiment:\n",
    "    \n",
    "    def __init__(self, step_size=None, delta=None, max_cosamp_iter=None, \n",
    "                 cosamp_tol=None, prop_sparsity=None, lamb=None, norm=None,\n",
    "                 function_budget=None, num_samples_constant=None, phi_cosamp=None,\n",
    "                 phi_lstsq=None, compessible_constant=None):\n",
    "        self.step_size = step_size\n",
    "        self.delta = delta\n",
    "        self.max_cosamp_iter = max_cosamp_iter\n",
    "        self.cosamp_tol = cosamp_tol\n",
    "        self.prop_sparsity = prop_sparsity\n",
    "        self.lamb = lamb\n",
    "        self.norm = norm\n",
    "        self.function_budget = function_budget\n",
    "        self.num_samples_constant=num_samples_constant\n",
    "        self.phi_cosamp=phi_cosamp\n",
    "        self.phi_lstsq=phi_lstsq\n",
    "        self.compessible_constant=compessible_constant\n",
    "        \n",
    "    def score(self, X, y):\n",
    "        return self.loss\n",
    "    \n",
    "    def get_params(self, deep=True):\n",
    "        return {\n",
    "            # Parameters for ZORO. \n",
    "            \"step_size\": self.step_size,\n",
    "            \"delta\": self.delta,\n",
    "            \"max_cosamp_iter\": self.max_cosamp_iter,\n",
    "            \"cosamp_tol\": self.cosamp_tol,\n",
    "            \"prop_sparsity\": self.prop_sparsity,\n",
    "            \"lamb\" : self.lamb,\n",
    "            \"norm\" : self.norm,\n",
    "            \"function_budget\" : self.function_budget,\n",
    "            \"num_samples_constant\": self.num_samples_constant,\n",
    "            \"phi_cosamp\": self.phi_cosamp,\n",
    "            \"phi_lstsq\": self.phi_lstsq,\n",
    "            \"compessible_constant\": self.compessible_constant,\n",
    "        }\n",
    "    \n",
    "    def set_params(self, **kwargs):\n",
    "        for parameter, value in kwargs.items():\n",
    "            setattr(self, parameter, value)\n",
    "        return self\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.report = []\n",
    "        \n",
    "        params = {\n",
    "            \"step_size\": self.step_size,\n",
    "            \"delta\": self.delta,\n",
    "            \"max_cosamp_iter\": self.max_cosamp_iter,\n",
    "            \"cosamp_tol\": self.cosamp_tol,\n",
    "            \"prop_sparsity\": self.prop_sparsity,\n",
    "            \"lamb\" : self.lamb,\n",
    "            \"norm\" : self.norm,\n",
    "            \"function_budget\" : self.function_budget,\n",
    "            \"num_samples_constant\": self.num_samples_constant,\n",
    "            \"phi_cosamp\": self.phi_cosamp,\n",
    "            \"phi_lstsq\": self.phi_lstsq,\n",
    "            \"compessible_constant\": self.compessible_constant,\n",
    "        }\n",
    "        \n",
    "        params[\"sparsity\"] = int(params[\"prop_sparsity\"] * X.shape[1])\n",
    "        params[\"num_samples\"] = int(np.ceil(np.log(X.shape[1])*params[\"sparsity\"]))\n",
    "\n",
    "        # Compute attack loss for each data point individually\n",
    "        for i in range(len(X)):\n",
    "            x0           = X[i, :]\n",
    "            xx0          = x0.copy()\n",
    "\n",
    "            label        = y[i]\n",
    "            label_attack = 1 - y[i]\n",
    "\n",
    "            obj_func = AttackLoss(\n",
    "                predictor=clf, \n",
    "                lamb=self.lamb, \n",
    "                norm=self.norm, \n",
    "                x_original=xx0,\n",
    "                y_true=label,\n",
    "                y_attack=label_attack\n",
    "            )\n",
    "\n",
    "            # initialize optimizer object\n",
    "            self.report.append([{\"evals\": 0, \"x\": x0, \"y\": label, \"loss\": obj_func(np.expand_dims(x0, 0))[0]}])\n",
    "            opt = optimizers.AdaZORO(x0, obj_func, params, function_budget=self.function_budget, function_target=0.001)\n",
    "\n",
    "            # the optimization routine\n",
    "            termination = False\n",
    "            while termination is False:\n",
    "                # optimization step\n",
    "                # solution_ZORO = False until a termination criterion is met, in which \n",
    "                # case solution_ZORO = the solution found.\n",
    "                # termination = False until a termination criterion is met.\n",
    "                # If ZORO terminates because function evaluation budget is met, \n",
    "                # termination = B\n",
    "                # If ZORO terminated because the target accuracy is met,\n",
    "                # termination= T.\n",
    "\n",
    "                opt.report(\"Step\")\n",
    "                evals_ZORO, solution_ZORO, termination = opt.step()\n",
    "\n",
    "                # save some useful values\n",
    "                self.report[-1].append({\"evals\" : evals_ZORO, \"x\": solution_ZORO, \"loss\": np.mean(opt.fd)})\n",
    "                # print some useful values\n",
    "                opt.report( f'Estimated f(x_{i}): %f  function evals: %d\\n' %\n",
    "                    (np.mean(opt.fd), evals_ZORO) )\n",
    "        self.loss = sum([self.report[i][-1][\"loss\"] for i in range(len(self.report))]) / len(self.report)\n",
    "    \n",
    "\n",
    "class ZOROExperiment:       \n",
    "    \n",
    "    def __init__(self, step_size=None, delta=None, max_cosamp_iter=None, \n",
    "                 cosamp_tol=None, prop_sparsity=None, lamb=None, norm=None,\n",
    "                 function_budget=None):\n",
    "        self.step_size = step_size\n",
    "        self.delta = delta\n",
    "        self.max_cosamp_iter = max_cosamp_iter\n",
    "        self.cosamp_tol = cosamp_tol\n",
    "        self.prop_sparsity = prop_sparsity\n",
    "        self.lamb = lamb\n",
    "        self.norm = norm\n",
    "        self.function_budget = function_budget\n",
    "        \n",
    "    def score(self, X, y):\n",
    "        return self.loss\n",
    "    \n",
    "    def get_params(self, deep=True):\n",
    "        return {\n",
    "            # Parameters for ZORO. \n",
    "            \"step_size\": self.step_size,\n",
    "            \"delta\": self.delta,\n",
    "            \"max_cosamp_iter\": self.max_cosamp_iter,\n",
    "            \"cosamp_tol\": self.cosamp_tol,\n",
    "            \"prop_sparsity\": self.prop_sparsity,\n",
    "            \"lamb\" : self.lamb,\n",
    "            \"norm\" : self.norm,\n",
    "            \"function_budget\" : self.function_budget\n",
    "        }\n",
    "    \n",
    "    def set_params(self, **kwargs):\n",
    "        for parameter, value in kwargs.items():\n",
    "            setattr(self, parameter, value)\n",
    "        return self\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.report = []\n",
    "        \n",
    "        params = {\n",
    "            \"step_size\": self.step_size,\n",
    "            \"delta\": self.delta,\n",
    "            \"max_cosamp_iter\": self.max_cosamp_iter,\n",
    "            \"cosamp_tol\": self.cosamp_tol,\n",
    "            \"prop_sparsity\": self.prop_sparsity,\n",
    "            \"lamb\" : self.lamb,\n",
    "            \"norm\" : self.norm,\n",
    "            \"function_budget\" : self.function_budget\n",
    "        }\n",
    "        \n",
    "        params[\"sparsity\"] = int(params[\"prop_sparsity\"] * X.shape[1])\n",
    "        params[\"num_samples\"] = int(np.ceil(np.log(X.shape[1])*params[\"sparsity\"]))\n",
    "\n",
    "        # Compute attack loss for each data point individually\n",
    "        for i in range(len(X)):\n",
    "            x0           = X[i, :]\n",
    "            xx0          = x0.copy()\n",
    "\n",
    "            label        = y[i]\n",
    "            label_attack = 1 - y[i]\n",
    "\n",
    "            obj_func = AttackLoss(\n",
    "                predictor=clf, \n",
    "                lamb=self.lamb, \n",
    "                norm=self.norm, \n",
    "                x_original=xx0,\n",
    "                y_true=label,\n",
    "                y_attack=label_attack\n",
    "            )\n",
    "\n",
    "            # initialize optimizer object\n",
    "            self.report.append([{\"evals\": 0, \"x\": x0, \"y\": label, \"loss\": obj_func(np.expand_dims(x0, 0))[0]}])\n",
    "            opt = optimizers.ZORO(x0, obj_func, params, function_budget=self.function_budget, function_target=0.001)\n",
    "\n",
    "            # the optimization routine\n",
    "            termination = False\n",
    "            while termination is False:\n",
    "                # optimization step\n",
    "                # solution_ZORO = False until a termination criterion is met, in which \n",
    "                # case solution_ZORO = the solution found.\n",
    "                # termination = False until a termination criterion is met.\n",
    "                # If ZORO terminates because function evaluation budget is met, \n",
    "                # termination = B\n",
    "                # If ZORO terminated because the target accuracy is met,\n",
    "                # termination= T.\n",
    "\n",
    "                evals_ZORO, solution_ZORO, termination = opt.step()\n",
    "\n",
    "                # save some useful values\n",
    "                self.report[-1].append({\"evals\" : evals_ZORO, \"x\": solution_ZORO, \"loss\": np.mean(opt.fd)})\n",
    "                # print some useful values\n",
    "                #opt.report( f'Estimated f(x_{i}): %f  function evals: %d\\n' %\n",
    "                #    (np.mean(opt.fd), evals_ZORO) )\n",
    "        self.loss = sum([self.report[i][-1][\"loss\"] for i in range(len(self.report))]) / len(self.report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters to search for ZORO attack\n",
    "params = {\n",
    "    \"step_size\": [1e-3, 1e-2, 1e-1, 1e0, 1e1, 1e2],\n",
    "    \"delta\": [1e-3, 1e-4, 1e-5], \n",
    "    \"max_cosamp_iter\": [5, 10, 15, 20],\n",
    "    \"cosamp_tol\": [0.5], \n",
    "    \"prop_sparsity\": [0.05, 0.10, 0.15, 0.20, 0.25], \n",
    "    \"lamb\" : [0.1], \n",
    "    \"norm\" : [2],\n",
    "    \"function_budget\": [5e4] # for hyperparameter tuning, we give this as a budget\n",
    "}\n",
    "\n",
    "adaparams = {\n",
    "    \"step_size\": [1e-3, 1e-2, 1e-1, 1e0, 1e1, 1e2],\n",
    "    \"delta\": [1e-3, 1e-4, 1e-5], \n",
    "    \"max_cosamp_iter\": [5, 10, 15, 20],\n",
    "    \"cosamp_tol\": [0.5], \n",
    "    \"prop_sparsity\": [0.05, 0.10, 0.15, 0.20, 0.25], \n",
    "    \"lamb\" : [0.1], \n",
    "    \"norm\" : [2],\n",
    "    \"function_budget\": [5e3], # for hyperparameter tuning, we give this as a budget\n",
    "    \"num_samples_constant\": [dim], \n",
    "    \"phi_cosamp\": [0.2, 0.4, 0.6, 0.8],\n",
    "    \"phi_lstsq\": [0.05, 0.1, 0.15, 0.20, 0.25],\n",
    "    \"compessible_constant\": [1, 1.1, 1.25, 1.5, 2]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_search = sklearn.model_selection.RandomizedSearchCV(\n",
    "    estimator = AdaZOROExperiment(),\n",
    "    param_distributions = adaparams,\n",
    "    n_iter = 100, # Run 100 random trials\n",
    "    n_jobs = 20, # Run 20 jobs at once\n",
    "    refit = False,\n",
    "    cv = ShuffleSplit(n_splits=1, train_size=16, random_state=42), # We attack the same 16 examples for every trial\n",
    "    error_score=np.nan\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# With dimension = 1000, this takes about 30 minutes to run on a machine with 32 CPU cores and 64 GB of memory.\n",
    "search_results = clf_search.fit(X, y) # Make sure to clear the output of this cell before saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# We see NaNs when numerical errors due to overflow occur (indicates a terrible hyperparam combination)\n",
    "pd.DataFrame(search_results.cv_results_).sort_values(\"mean_test_score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Best Model With Higher Budget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = ShuffleSplit(n_splits=1, train_size=16, random_state=42)\n",
    "# Recover the exact indices used for training (kind of hacky)\n",
    "for train_index, test_index in rs.split(X):\n",
    "    X_sel, y_sel = X[train_index], y[train_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = search_results.cv_results_[\"params\"][0]\n",
    "best_params.update({\"function_budget\" : 5e5})\n",
    "best_exp = ZOROExperiment(**best_params)\n",
    "best_exp.fit(X_sel[:16,:], y_sel[:16])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save Reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(best_exp.report, \"gaussian_d1000_20220616_report.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reload Best Attacker Data and Plot Graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fig 1\n",
    "\n",
    "PCA of Data Points, Four Groupings:\n",
    "1. Original Cluster 1\n",
    "2. Original Cluster 2\n",
    "3. Attack Points 1->2\n",
    "4. Attack Points 2->1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fig 2\n",
    "\n",
    "PCA of Example Point:\n",
    "1. Original Cluster 1\n",
    "2. Original Cluster 2\n",
    "3. Trace of Attack over Iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fig 3\n",
    "\n",
    "Distance from Hyperplane (Vector Norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fig 4\n",
    "\n",
    "Distance from Input to Attack Vector (Vector Norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fig 5\n",
    "\n",
    "Movement in Hyperplane Direction Norm versus Total Movement Norm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-yeast-raytune2]",
   "language": "python",
   "name": "conda-env-.conda-yeast-raytune2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
